{
 "cells": [
  {
   "cell_type": "code",
   "id": "1029fe18e1b3ee45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-07T21:09:39.276780Z",
     "start_time": "2025-02-07T21:09:39.086173Z"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "spark = SparkSession.builder.appName(\"Netfilx data analysis\").getOrCreate()\n",
    "print(spark.version)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d9665e9e1535b1eb",
   "metadata": {},
   "source": "file_path = \"/data/netflix_titles.csv\"  # Use forward slashes or double backslashes",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7461c3b8e23a8a73",
   "metadata": {},
   "source": [
    "netflix_data = spark.read.format('csv').option('header', 'true').option('inferSchema', True).load(file_path)\n",
    "netflix_data.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69fc72b48bb8f9f2",
   "metadata": {},
   "source": [
    "total_rows = netflix_data.count()\n",
    "print(f\"Total rows: {total_rows}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b3037484bb2cdff8",
   "metadata": {},
   "source": [
    "for c in netflix_data.columns:\n",
    "    null_count = netflix_data.filter(col(c).isNull()).count()\n",
    "    print(f\"Column '{c}': {null_count} nulls\")\n",
    "    percentage_null = null_count / total_rows * 100\n",
    "    print(f\"Column '{c}': {percentage_null} %\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6c96e0c45406437f",
   "metadata": {},
   "source": [
    "netflix_data_null_fill=netflix_data.na.fill({'director':'Unknown',\n",
    "                      'cast':'Unknown','country':'Unknown'})\n",
    "netflix_data_null_fill.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e860499fd202de01",
   "metadata": {},
   "source": [
    "for c in netflix_data.columns:\n",
    "    null_count = netflix_data_null_fill.filter(col(c).isNull()).count()\n",
    "    percentage_null = null_count / total_rows * 100\n",
    "    print(f\"Column '{c}': {percentage_null} %\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e619176d60500f6a",
   "metadata": {},
   "source": [
    "netflix_nulls_drop = netflix_data_null_fill.na.drop()\n",
    "netflix_nulls_drop.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9a88ce864d38192",
   "metadata": {},
   "source": [
    "netflix_nulls_drop.filter(col('type') == 'Movie').select('listed_in').show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "83a9bd5cf60fa78d",
   "metadata": {},
   "source": [
    "netflix_nulls_drop.filter(col('type') == 'TV Show').select('listed_in').show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "36e747ff0da3bc5",
   "metadata": {},
   "source": [
    "show_movie_type_df = netflix_nulls_drop.withColumn(\"movie_type\",when(col(\"type\") == \"Movie\", when(col(\"listed_in\").contains(\"International\"), \"Global\").otherwise(\"Local\"))\n",
    "                              ).withColumn(\"show_type\",when(col(\"type\") == \"TV Show\", when(col(\"listed_in\").contains(\"International\"), \"Global\").otherwise(\"Local\")))\n",
    "show_movie_type_df.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b2fcc8afe50e440",
   "metadata": {},
   "source": [
    "genre_df = show_movie_type_df.withColumn(\"genres\", split(show_movie_type_df[\"listed_in\"], \",\\\\s*\")).drop('listed_in')  # Split by comma and whitespace\n",
    "genre_df.select('genres').show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "431421225f15b97",
   "metadata": {},
   "source": [
    "tsa_columns_gen_df = genre_df.withColumn('added_date', to_date(genre_df['date_added'], \"MMMM d, yyyy\"))\n",
    "# Extract year, month, date, and day_of_week\n",
    "tsa_columns_gen_df = tsa_columns_gen_df.withColumn(\"year\", date_format(col(\"added_date\"), \"yyyy\")) \\\n",
    "       .withColumn(\"month\", date_format(col(\"added_date\"), \"MMMM\")) \\\n",
    "       .withColumn(\"day\", date_format(col(\"added_date\"), \"d\")) \\\n",
    "       .withColumn(\"day_of_week\", date_format(col(\"added_date\"), \"EEEE\"))\n",
    "\n",
    "tsa_columns_gen_df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "796555a393fcdb1c",
   "metadata": {},
   "source": [
    "country_split_df = (tsa_columns_gen_df.withColumn(\"country\", regexp_replace(col('country'), r'^\\s*,\\s*', ''))\n",
    "                    .withColumn(\"countries\", split(\"country\", r\",\\s*\")))\n",
    "country_explode_df = country_split_df.withColumn(\"country\", explode_outer(country_split_df[\"countries\"]))\n",
    "country_explode_df.select('country','countries').show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bee4704c29036e5e",
   "metadata": {},
   "source": [
    "valid_country_file_path = r\"/data/valid_countries.txt\"\n",
    "valid_countries_df = spark.read.format('csv').option('header', 'true').option('inferSchema', True).load(valid_country_file_path)\n",
    "\n",
    "# 2. Clean the country column\n",
    "cleaned_df = country_explode_df.join(valid_countries_df, country_explode_df[\"country\"] == valid_countries_df[\"country\"], \"left_anti\")\n",
    "\n",
    "invalid_countries = list(set([row.country for row in cleaned_df.collect()]))\n",
    "\n",
    "invalid_countries"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b07f4843bbcd03d3",
   "metadata": {},
   "source": [
    "country_clean_df = country_explode_df.withColumn(\n",
    "    'country_clean',\n",
    "    when(col(\"country\").isin(invalid_countries), array(lit('Unknown'))).otherwise(col('countries'))\n",
    ").drop('countries')\n",
    "\n",
    "country_clean_df.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96f5218151394417",
   "metadata": {},
   "source": [
    "# Step 1: Read the JSON file into a DataFrame\n",
    "lang_map_file_path = r\"/data/countries_languages.json\"\n",
    "lang_map_df = spark.read.option(\"multiline\", \"true\").json(lang_map_file_path)\n",
    "\n",
    "lang_map_df.show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c0b41dc681844ae9",
   "metadata": {},
   "source": [
    "join_df = lang_map_df.join(country_clean_df, 'country', \"inner\")\n",
    "join_df.select('country','Languages','country_clean').show(truncate=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f96938ae5860258",
   "metadata": {},
   "source": [
    "df_exploded = join_df.withColumn(\"Language\", explode(\"Languages\"))\n",
    "\n",
    "# Group by country_clean and collect the languages into a list\n",
    "languages_df = df_exploded.groupBy(\"country_clean\").agg(collect_list(\"Language\").alias(\"Languages_array\"))\n",
    "# Distinct the languages in Languages_array\n",
    "languages_df = languages_df.withColumn(\"Languages_array\", array_distinct(col(\"Languages_array\")))\n",
    "languages_df.show(truncate=False)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Join back with the original DataFrame\n",
    "result_df = join_df.join(languages_df, \"country_clean\", \"left\")\n",
    "result_df.select('country_clean','Country','Languages_array','Languages').show(truncate=False)"
   ],
   "id": "8359143dab7ec18c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result_df_cols_dropped = result_df.drop('Country','Languages').withColumnRenamed('country_clean','released_countries').withColumnRenamed('Languages_array','released_languages').dropDuplicates()\n",
    "result_df_cols_dropped.select('show_id','released_countries','released_languages').show(truncate=False)"
   ],
   "id": "8a388d86cc7a87a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result_df_cols_dropped=result_df_cols_dropped.withColumn('release_year', col('release_year').cast('Integer'))\n",
    "result_df_cols_dropped.show(truncate=False)"
   ],
   "id": "184123d37a227513",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Transform 'duration' column for movies and TV shows\n",
    "durations_df = (\n",
    "    result_df_cols_dropped\n",
    "    .withColumn(\n",
    "        'movie_duration',\n",
    "        when(col('type') == 'Movie', regexp_replace(col('duration'), ' min', '').cast('Integer'))\n",
    "        .otherwise(lit(None))  # Use None for NULL values\n",
    "    )\n",
    "    .withColumn(\n",
    "        'seasons',\n",
    "        when(col('type') == 'TV Show', regexp_replace(col('duration'), r'\\D', '').cast('Integer'))\n",
    "        .otherwise(lit(None))\n",
    "    )\n",
    ").drop('duration')\n",
    "\n",
    "# Display the results\n",
    "durations_df.show(truncate=False)\n"
   ],
   "id": "869c8dad1a1808a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns = [\n",
    "    'show_id',\n",
    "    'type',\n",
    "    'title',\n",
    "    'director',\n",
    "    'cast',\n",
    "    'date_added',\n",
    "    'release_year',\n",
    "    'rating',\n",
    "    'movie_duration',\n",
    "    'seasons',\n",
    "    'description',\n",
    "    'released_countries',\n",
    "    'released_languages',  # Missing comma was added here\n",
    "    'movie_type',\n",
    "    'show_type',\n",
    "    'genres',\n",
    "    'added_date',\n",
    "    'year',\n",
    "    'month',\n",
    "    'day',\n",
    "    'day_of_week'\n",
    "]\n",
    "netflix_ordered_select = durations_df.select(*columns)\n",
    "netflix_ordered_select.show()"
   ],
   "id": "57abfc8f6d389afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "OUTPUT_PATH = '/target_data'\n",
    "netflix_ordered_select.write.format('parquet').mode('overwrite').save(OUTPUT_PATH)"
   ],
   "id": "da8fd806f6e4b84a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "netflix_cleaned_data = spark.read.parquet(OUTPUT_PATH)\n",
    "netflix_cleaned_data.show(truncate=False)"
   ],
   "id": "e1840cff68e4a954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "netflix_ordered_select.printSchema()",
   "id": "2cfee264cf6ec23d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b1da1687410f6861",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
